{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c69a2c63",
   "metadata": {
    "papermill": {
     "duration": 5.240952,
     "end_time": "2023-06-30T10:47:31.336913",
     "exception": false,
     "start_time": "2023-06-30T10:47:26.095961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import sys\n",
    "import json\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "sys.path.append(\"/kaggle/input/detection-wheel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5c62c96",
   "metadata": {
    "papermill": {
     "duration": 0.954499,
     "end_time": "2023-06-30T10:47:32.298961",
     "exception": false,
     "start_time": "2023-06-30T10:47:31.344462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin   cuda-11.7  games\t  lib  project_templates  share  waved\n",
      "cuda  etc\t include  man  sbin\t\t  src\t www\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__  #torch 2.0\n",
    "#!nvidia-smi   #CUDA Version: 11.4\n",
    "! ls /usr/local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dc1fc41",
   "metadata": {
    "papermill": {
     "duration": 281.361058,
     "end_time": "2023-06-30T10:52:13.667061",
     "exception": false,
     "start_time": "2023-06-30T10:47:32.306003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # # Install pycocotools package\n",
    "# import os\n",
    "# !mkdir /kaggle/working/packages\n",
    "# !cp -r /kaggle/input/pycocotools/* /kaggle/working/packages\n",
    "# os.chdir(\"/kaggle/working/packages/pycocotools-2.0.6/\")\n",
    "# !python setup.py install -q\n",
    "# !pip install . --no-index --find-links /kaggle/working/packages/ -q\n",
    "# # # Install mmcv and mmdet packages\n",
    "# # #3.0\n",
    "# # #!pip install mmcv mmdet --no-index --find-links /kaggle/input/mmdetection/ -q\n",
    "# # #os.chdir(\"/kaggle/working\")\n",
    "# # #ytt 2140\n",
    "# # !pip install '/kaggle/input/mmdetectionv2140/addict-2.4.0-py3-none-any.whl' --no-deps\n",
    "# # !pip install '/kaggle/input/mmdetectionv2140/yapf-0.31.0-py2.py3-none-any.whl' --no-deps\n",
    "# # !pip install '/kaggle/input/mmdetectionv2140/terminal-0.4.0-py3-none-any.whl' --no-deps\n",
    "# # !pip install '/kaggle/input/mmdetectionv2140/terminaltables-3.1.0-py3-none-any.whl' --no-deps\n",
    "# # !pip install '/kaggle/input/mmdetectionv2140/mmcv_full-1_3_8-cu110-torch1_7_0/mmcv_full-1.3.8-cp37-cp37m-manylinux1_x86_64.whl' --no-deps\n",
    "# # !pip install '/kaggle/input/mmdetectionv2140/pycocotools-2.0.2/pycocotools-2.0.2' --no-deps\n",
    "# # !pip install '/kaggle/input/mmdetectionv2140/mmpycocotools-12.0.3/mmpycocotools-12.0.3' --no-deps\n",
    "\n",
    "# # !rm -rf mmdetection\n",
    "\n",
    "# # !cp -r /kaggle/input/mmdetectionv2140/mmdetection-2.14.0 /kaggle/working/\n",
    "# # !mv /kaggle/working/mmdetection-2.14.0 /kaggle/working/mmdetection\n",
    "# # %cd /kaggle/working/mmdetection\n",
    "# # !pip install -e .\n",
    "\n",
    "\n",
    "# # 必要なライブラリのインストール（オフライン用）\n",
    "# !pip install /kaggle/input/mmdetection-2-26-0/mmdetection-2-26-0/addict-2.4.0-py3-none-any.whl\n",
    "# !pip install /kaggle/input/mmdetection-2-26-0/mmdetection-2-26-0/yapf-0.32.0-py2.py3-none-any.whl\n",
    "# !pip install /kaggle/input/mmdetection-2-26-0/mmdetection-2-26-0/terminal-0.4.0-py3-none-any.whl\n",
    "# !pip install /kaggle/input/mmdetection-2-26-0/mmdetection-2-26-0/terminaltables-3.1.10-py2.py3-none-any.whl\n",
    "# #ytt\n",
    "# #!pip install /kaggle/input/2023-hhp-mmdet/mmcv_full-1.7.0-cp310-cp310-manylinux1_x86_64_cu113.whl\n",
    "# !pip install /kaggle/input/mmdet3-wheels/mmcv_full-1.7.1-cp310-cp310-linux_x86_64.whl\n",
    "# #!pip install /kaggle/input/mmdetection-2-26-0/mmdetection-2-26-0/mmcv_full-1.7.0-cp37-cp37m-linux_x86_64.whl\n",
    "# #!pip install /kaggle/input/mmdetection-2-26-0/mmdetection-2-26-0/pycocotools-2.0.6-cp37-cp37m-linux_x86_64.whl\n",
    "# #!pip install /kaggle/input/mmdetection-2-26-0/mmdetection-2-26-0/mmpycocotools-12.0.3-cp37-cp37m-linux_x86_64.whl\n",
    "\n",
    "# !cp -r /kaggle/input/mmdetection-2-26-0/mmdetection-2-26-0/mmdetection/ /kaggle/working/\n",
    "# %cd /kaggle/working/mmdetection\n",
    "# !pip install -e . --no-deps\n",
    "# %cd /kaggle/working/\n",
    "\n",
    "# !pip install /kaggle/input/mmdetection-2-26-0/mmdetection-2-26-0/mmdet-2.26.0-py3-none-any.whl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e38ba5b",
   "metadata": {
    "papermill": {
     "duration": 0.028284,
     "end_time": "2023-06-30T10:52:13.706128",
     "exception": false,
     "start_time": "2023-06-30T10:52:13.677844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import numpy as np\n",
    "from pycocotools import _mask as coco_mask\n",
    "import typing as t\n",
    "import zlib\n",
    "\n",
    "def encode_binary_mask(mask: np.ndarray) -> t.Text:\n",
    "  \"\"\"Converts a binary mask into OID challenge encoding ascii text.\"\"\"\n",
    "\n",
    "  # check input mask --\n",
    "  if mask.dtype != np.bool:\n",
    "    raise ValueError(\n",
    "        \"encode_binary_mask expects a binary mask, received dtype == %s\" %\n",
    "        mask.dtype)\n",
    "\n",
    "  mask = np.squeeze(mask)\n",
    "  if len(mask.shape) != 2:\n",
    "    raise ValueError(\n",
    "        \"encode_binary_mask expects a 2d mask, received shape == %s\" %\n",
    "        mask.shape)\n",
    "\n",
    "  # convert input mask to expected COCO API input --\n",
    "  mask_to_encode = mask.reshape(mask.shape[0], mask.shape[1], 1)\n",
    "  mask_to_encode = mask_to_encode.astype(np.uint8)\n",
    "  mask_to_encode = np.asfortranarray(mask_to_encode)\n",
    "\n",
    "  # RLE encode mask --\n",
    "  encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n",
    "\n",
    "  # compress and base64 encoding --\n",
    "  binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n",
    "  base64_str = base64.b64encode(binary_str)\n",
    "  return base64_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ce576f1",
   "metadata": {
    "papermill": {
     "duration": 0.037357,
     "end_time": "2023-06-30T10:52:13.753806",
     "exception": false,
     "start_time": "2023-06-30T10:52:13.716449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class PennFudanDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, imgs, transforms):\n",
    "        self.transforms = transforms\n",
    "        # load all image files, sorting them to\n",
    "        # ensure that they are aligned\n",
    "        self.imgs = imgs\n",
    "        self.name_indices = [os.path.splitext(os.path.basename(i))[0] for i in imgs]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # load images and masks\n",
    "        img_path = self.imgs[idx]\n",
    "        name = self.name_indices[idx]\n",
    "        array = tiff.imread(img_path)\n",
    "        img = Image.fromarray(array)\n",
    "        \n",
    "        img, _ = self.transforms(img, img)\n",
    "\n",
    "        return img, name\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d68c9a53",
   "metadata": {
    "papermill": {
     "duration": 0.034849,
     "end_time": "2023-06-30T10:52:13.809714",
     "exception": false,
     "start_time": "2023-06-30T10:52:13.774865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torchvision\n",
    "# import torchvision\n",
    "# from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "# from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "# def get_model_instance_segmentation(num_classes):\n",
    "#     # load an instance segmentation model pre-trained on COCO\n",
    "#     model = torchvision.models.detection.maskrcnn_resnet50_fpn_v2(weights=None, weights_backbone=None)\n",
    "\n",
    "#     # get number of input features for the classifier\n",
    "#     in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "#     # replace the pre-trained head with a new one\n",
    "#     model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "#     # now get the number of input features for the mask classifier\n",
    "#     in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "#     hidden_layer = 256\n",
    "#     # and replace the mask predictor with a new one\n",
    "#     model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n",
    "#                                                        hidden_layer,\n",
    "#                                                        num_classes)\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78b9bb09-9347-4454-8242-8a290d53aaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mmdet==2.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2a4c11f-af25-4406-8f60-79ac21054633",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03633c9-4f8d-4831-9eda-c45d343b5f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "676fceda-b35e-4366-a6ac-4c034a912e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('ex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46c985ed",
   "metadata": {
    "papermill": {
     "duration": 0.250159,
     "end_time": "2023-06-30T10:52:14.075993",
     "exception": false,
     "start_time": "2023-06-30T10:52:13.825834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transforms as T\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.PILToTensor())\n",
    "    transforms.append(T.ConvertImageDtype(torch.float))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20003285",
   "metadata": {
    "papermill": {
     "duration": 0.038862,
     "end_time": "2023-06-30T10:52:14.125767",
     "exception": false,
     "start_time": "2023-06-30T10:52:14.086905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from engine import train_one_epoch, evaluate\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd18dba5",
   "metadata": {
    "papermill": {
     "duration": 0.039426,
     "end_time": "2023-06-30T10:52:14.175542",
     "exception": false,
     "start_time": "2023-06-30T10:52:14.136116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1202bd3b-ea99-42a3-b79e-83941fbb6f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/nischay/hubmap', '/usr/lib/python38.zip', '/usr/lib/python3.8', '/usr/lib/python3.8/lib-dynload', '', '/root/.local/lib/python3.8/site-packages', '/usr/local/lib/python3.8/dist-packages', '/usr/local/lib/python3.8/dist-packages/ocotillo-1.0.5.1-py3.8.egg', '/usr/local/lib/python3.8/dist-packages/audio2numpy-0.1.2-py3.8.egg', '/home/nischay/hubmap/vitadap/detection', '/usr/lib/python3/dist-packages', '/kaggle/input/detection-wheel', 'ex']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import importlib\n",
    "# importlib.reload(mmdet)\n",
    "# sys.path.append('/home/nischay/hubmap/try_mm/mmdetection/')\n",
    "# !sudo pip uninstall -y mmdet \n",
    "# sys.path.insert(0, '/home/nischay/hubmap/try_mm/mmdetection/cbnet')\n",
    "sys.path.insert(9,'/home/nischay/hubmap/vitadap/detection')\n",
    "# !cd /home/nischay/hubmap/try_mm/mmdetection/cbnet && sudo pip install -v -e .\n",
    "# !pip install -e .\n",
    "import mmdet\n",
    "from mmdet.apis import init_detector, inference_detector,show_result_pyplot, set_random_seed\n",
    "from mmdet.models import build_detector\n",
    "#print(mmdet.__version__)\n",
    "#print(mmcv.__version__)\n",
    "#print(mmengine.__version__)\n",
    "\n",
    "from mmdet.models.backbones import *\n",
    "# # #check file her\n",
    "\n",
    "from mmcv import Config\n",
    "\n",
    "from mmdet.models.backbones.swin import SwinTransformer\n",
    "from mmdet.models.backbones import cbnet\n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2285ab9d-8d49-4a9d-abad-b41e881f8be5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e315cc52",
   "metadata": {
    "papermill": {
     "duration": 3.291919,
     "end_time": "2023-06-30T10:52:17.518921",
     "exception": false,
     "start_time": "2023-06-30T10:52:14.227002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import mmdet, mmcv, mmengine\n",
    "#from mmengine.config import Config\n",
    "#from mmengine.runner import Runner\n",
    "#from mmdet.utils import register_all_modules\n",
    "#from mmdet.apis import init_detector, inference_detector\n",
    "#from mmengine.visualization import Visualizer\n",
    "\n",
    "from mmdet.apis import init_detector, inference_detector,show_result_pyplot, set_random_seed\n",
    "\n",
    "#print(mmdet.__version__)\n",
    "#print(mmcv.__version__)\n",
    "#print(mmengine.__version__)\n",
    "\n",
    "\n",
    "# # #check file her\n",
    "\n",
    "from mmcv import Config\n",
    "\n",
    "config_file = '/home/nischay/hubmap/vitadap/detection/work_dirs/hubmap/pretwsiallhtc_resnext101_exp3_augv4_maskloss4/detec101next.py'\n",
    "cfg = Config.fromfile(config_file )\n",
    "\n",
    "\n",
    "\n",
    "cfg.data.test.pipeline[1].img_scale= [(2048, 2048)]#train 1280-1600 , inf 1280-4000 -> 1440,2520,3600#\n",
    "\n",
    "#test cfg\n",
    "#cfg.model.test_cfg.rcnn.max_per_img = 1000\n",
    "#cfg.model.test_cfg.rcnn.nms.iou_threshold=0.3\n",
    "#cfg.model.test_cfg.rcnn.mask_thr_binary=0.45\n",
    "\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "#print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06375b6c",
   "metadata": {
    "papermill": {
     "duration": 0.019102,
     "end_time": "2023-06-30T10:52:17.548758",
     "exception": false,
     "start_time": "2023-06-30T10:52:17.529656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "[{'type': 'LoadImageFromFile'}, {'type': 'MultiScaleFlipAug', 'img_scale': [(2048, 2048)], 'flip': True, 'flip_direction': ['horizontal', 'vertical'], 'transforms': [{'type': 'Resize', 'keep_ratio': True}, {'type': 'RandomFlip'}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}]\n"
     ]
    }
   ],
   "source": [
    "print(f'Config:\\n{cfg.data.test.pipeline}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a181d819-55ba-468f-b63f-124363050a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eeed970b-915c-4760-9242-077f3ac5b2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d541894-264e-436d-b58d-2fb958944036",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('coco/folds5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee4f105c-6f09-4880-90d2-789dd3918e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = df[df['fold']==1]['id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b1427d-7e2b-4729-b885-de3a81bf1220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ad27153-b9bd-455c-9af2-82e3011dd924",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = pd.read_csv('/home/nischay/hubmap/Data/tile_meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a12fe640-5f8e-4c75-85ba-980ce4cee572",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2916174/142878037.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  tiles = tiles[tiles['dataset']==3][tiles['source_wsi']<8].reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "tiles = tiles[tiles['dataset']==3][tiles['source_wsi']<8].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeb832d-fc2b-418d-9146-67d08b8e1c29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e1ea9d-4cb2-4be4-834b-a7c0e4cef77b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4ec4b61-82d0-4aa6-8fa6-bf88b27faf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "from pathlib import Path\n",
    "annFile = f\"/home/nischay/hubmap/coco/ds1_coco_1024_valid_all_fold1.json\"\n",
    "\n",
    "# colors = ['Set1'] \n",
    "# legend = ids_categories #{1: 'blood_vessel'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f08cb811-cf3b-49ba-b802-56c2200e8ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco_gt = COCO(annFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42716052-bfcc-4092-97d1-94eeca12016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ids = tiles['id'].tolist()\n",
    "val_ids = ['/home/nischay/hubmap/Data/train/'+i+'.tif' for i in val_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0cb92a95",
   "metadata": {
    "papermill": {
     "duration": 21.084127,
     "end_time": "2023-06-30T10:52:38.643122",
     "exception": false,
     "start_time": "2023-06-30T10:52:17.558995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: /home/nischay/hubmap/vitadap/detection/work_dirs/hubmap/pretwsiallhtc_resnext101_exp3_augv4_maskloss4/best_segm_mAP_epoch_17.pth\n"
     ]
    }
   ],
   "source": [
    "# checkpoint_file = '/home/nischay/hubmap/try_mm/mmdetection/work_dirs/hubmap/pretexp1_ds1ft_20e_2048_htc101/best_segm_mAP_epoch_14.pth'\n",
    "# checkpoint_file = '/home/nischay/hubmap/try_mm/mmdetection/work_dirs/hubmap/pretexp10_ds1ft_20e_2048_htc101_pretdsall/best_segm_mAP_epoch_19.pth'\n",
    "checkpoint_file = '/home/nischay/hubmap/vitadap/detection/work_dirs/hubmap/pretwsiallhtc_resnext101_exp3_augv4_maskloss4/best_segm_mAP_epoch_17.pth'\n",
    "#model = init_detector(config_file, checkpoint_file, device=device)  # or device='cuda:0'\n",
    "model = init_detector(cfg, checkpoint_file, device=device)  # or device='cuda:0'\n",
    "# model = get_model_instance_segmentation(num_classes=2)\n",
    "# model.to(device)\n",
    "# model.load_state_dict(torch.load('/kaggle/input/hubmap-train/fold_0_epoch5.pth'))\n",
    "# model.eval()\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52d95ac5",
   "metadata": {
    "papermill": {
     "duration": 0.021091,
     "end_time": "2023-06-30T10:52:38.675018",
     "exception": false,
     "start_time": "2023-06-30T10:52:38.653927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_imgs = val_ids #glob.glob('/kaggle/input/hubmap-hacking-the-human-vasculature/test/*.tif')\n",
    "dataset_test = PennFudanDataset(all_imgs, get_transform(train=False))\n",
    "test_dl = torch.utils.data.DataLoader(\n",
    "        dataset_test, batch_size=1, shuffle=False, num_workers=os.cpu_count(), pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c129ad17",
   "metadata": {
    "papermill": {
     "duration": 0.018495,
     "end_time": "2023-06-30T10:52:38.704057",
     "exception": false,
     "start_time": "2023-06-30T10:52:38.685562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb9e2c3",
   "metadata": {
    "papermill": {
     "duration": 0.017742,
     "end_time": "2023-06-30T10:52:38.732107",
     "exception": false,
     "start_time": "2023-06-30T10:52:38.714365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5a54d40-2805-4326-b977-ca0e838d6a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67370624-568e-4de6-be72-4e1117f710e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (pred[0][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c32d1920",
   "metadata": {
    "papermill": {
     "duration": 8.1193,
     "end_time": "2023-06-30T10:52:46.861955",
     "exception": false,
     "start_time": "2023-06-30T10:52:38.742655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1200 [00:00<?, ?it/s]/home/nischay/hubmap/vitadap/detection/mmdet/datasets/utils.py:66: UserWarning: \"ImageToTensor\" pipeline is replaced by \"DefaultFormatBundle\" for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n",
      "  warnings.warn(\n",
      "/home/nischay/hubmap/vitadap/detection/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py:245: UserWarning: Scale_factor should be a Tensor or ndarray with shape (4,), float would be deprecated. \n",
      "  warn('Scale_factor should be a Tensor or ndarray '\n",
      "100%|███████████████████████████████████████| 1200/1200 [53:09<00:00,  2.66s/it]\n"
     ]
    }
   ],
   "source": [
    "sample = None\n",
    "import mmcv\n",
    "\n",
    "ids = []\n",
    "heights = []\n",
    "widths = []\n",
    "prediction_strings = []\n",
    "confidence_thresholds = {0: 0.5, 1: 0.5, 2: 0.8}\n",
    "\n",
    "for img in tqdm(all_imgs):\n",
    "    img_array = mmcv.imread(img,channel_order='rgb')\n",
    "    [h, w, c] = img_array.shape \n",
    "    pred = inference_detector(model,img)\n",
    "    pred_string = ''\n",
    "    #print(pred.pred_instances)\n",
    "    #print (len(pred)) #2\n",
    "    #print(pred)\n",
    "    \n",
    "    pred_class = pred[0]\n",
    "#     print(len(pred_class)) #3 class\n",
    "#     print(pred_class)\n",
    "#     print(pred_class[0].shape) #(5,5) #class 0 with 5 item\n",
    "#     print(pred_class[1].shape) #(40,5)#class 1 with 40 item\n",
    "#     print(pred_class[2].shape) #(1,5) #class 2 with 1 item\n",
    "    #print(pred.pred_instances)\n",
    "    \n",
    "    pred_mask = pred[1]\n",
    "\n",
    "                        \n",
    "    ids.append(os.path.basename(img).split('.')[0])\n",
    "    heights.append(h)\n",
    "    widths.append(w)\n",
    "    prediction_strings.append(pred)                    \n",
    "    \n",
    "    # prediction_strings.append(pred_string)                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6abb31e5-9fa7-4982-af7d-20a1890e2b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: /home/nischay/hubmap/try_mm/mmdetection/cbnet/work_dirs/hubmap/pseudo_exp1_withpret_cbbase_1600_morepretep/best_segm_mAP_epoch_15.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1200/1200 [27:12<00:00,  1.36s/it]\n"
     ]
    }
   ],
   "source": [
    "config_file2 = '/home/nischay/hubmap/try_mm/mmdetection/cbnet/work_dirs/hubmap/pseudo_exp1_withpret_cbbase_1600_morepretep/exp1_cbnet_swinb.py'\n",
    "\n",
    "cfg2 = Config.fromfile(config_file2)\n",
    "\n",
    "cfg2.data.test.pipeline[1].img_scale= [(1600, 1600)]#train 1280-1600 , inf 1280-4000 -> 1440,2520,3600#\n",
    "cfg2.model.test_cfg.rcnn.score_thr = 0.001\n",
    "\n",
    "cfg2.model.test_cfg.rcnn.max_per_img = 100\n",
    "cfg2.model.test_cfg.rcnn.nms.type='nms'\n",
    "cfg2.model.test_cfg.rcnn.nms.iou_threshold=0.5\n",
    "\n",
    "cfg2.model.test_cfg.rcnn.mask_thr_binary=0.5\n",
    "\n",
    "cfg2.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "#print(f'Config:\\n{cfg.pretty_text}')\n",
    "\n",
    "\n",
    "# checkpoint_file2 = '/home/nischay/hubmap/try_mm/mmdetection/work_dirs/hubmap/pseudo/pseudo60combpretexp5_ds1ft_20e_2048_htc50/best_segm_mAP_epoch_15.pth'\n",
    "# checkpoint_file2 = '/home/nischay/hubmap/try_mm/mmdetection/work_dirs/hubmap/pseudo/pseudo60combpretexp5_ds1ft_20e_2048_htc50_augv3/detectors_epoch_23.pth'\n",
    "checkpoint_file2 = '/home/nischay/hubmap/try_mm/mmdetection/cbnet/work_dirs/hubmap/pseudo_exp1_withpret_cbbase_1600_morepretep/best_segm_mAP_epoch_15.pth'\n",
    "model2 = init_detector(cfg2, checkpoint_file2, device=device)  # or device='cuda:0'\n",
    "\n",
    "\n",
    "\n",
    "sample = None\n",
    "import mmcv\n",
    "\n",
    "ids2 = []\n",
    "heights2 = []\n",
    "widths2 = []\n",
    "prediction_strings2 = []\n",
    "\n",
    "for img in tqdm(all_imgs):\n",
    "    img_array = mmcv.imread(img,channel_order='rgb')\n",
    "    [h, w, c] = img_array.shape \n",
    "    pred = inference_detector(model2,img)\n",
    "    pred_string = ''\n",
    "    #print(pred.pred_instances)\n",
    "    #print (len(pred)) #2\n",
    "    #print(pred)\n",
    "    \n",
    "    pred_class = pred[0]\n",
    "#     print(len(pred_class)) #3 class\n",
    "#     print(pred_class)\n",
    "#     print(pred_class[0].shape) #(5,5) #class 0 with 5 item\n",
    "#     print(pred_class[1].shape) #(40,5)#class 1 with 40 item\n",
    "#     print(pred_class[2].shape) #(1,5) #class 2 with 1 item\n",
    "    #print(pred.pred_instances)\n",
    "    \n",
    "    pred_mask = pred[1]\n",
    "\n",
    "                        \n",
    "    ids2.append(os.path.basename(img).split('.')[0])\n",
    "    heights2.append(h)\n",
    "    widths2.append(w)\n",
    "    prediction_strings2.append(pred)                    \n",
    "    \n",
    "    # prediction_strings.append(pred_string)                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7fbd0290-9143-44c8-bdd5-8cff730bd241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv_custom  # noqa: F401,F403\n",
    "import mmdet_custom  # noqa: F401,F403"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52f3b451-ece8-4062-9f53-3acc645c7e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: /home/nischay/hubmap/vitadap/detection/work_dirs/ds12combine/beitv2ladap_exp2/f1/best_segm_mAP_epoch_18.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1200/1200 [46:44<00:00,  2.34s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config_file3 = '/home/nischay/hubmap/vitadap/detection/hubconf/exp4_adapbeitv2l.py'\n",
    "\n",
    "cfg3 = Config.fromfile(config_file3)\n",
    "cfg3.data.test.pipeline\n",
    "\n",
    "cfg3.data.test.pipeline[1].img_scale= [(1400, 1400)]#train 1280-1600 , inf 1280-4000 -> 1440,2520,3600#\n",
    "cfg3.model.test_cfg.rcnn.score_thr = 0.001\n",
    "\n",
    "cfg3.model.test_cfg.rcnn.max_per_img = 100\n",
    "cfg3.model.test_cfg.rcnn.nms.type='nms'\n",
    "\n",
    "cfg3.model.test_cfg.rcnn.nms.iou_threshold=0.5\n",
    "cfg3.model.test_cfg.rcnn.mask_thr_binary=0.5\n",
    "\n",
    "# cfg3.data.test.pipeline[1].img_scale= [(1600, 1600)]#train 1280-1600 , inf 1280-4000 -> 1440,2520,3600#\n",
    "\n",
    "cfg3.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "#print(f'Config:\\n{cfg.pretty_text}')\n",
    "\n",
    "\n",
    "# checkpoint_file2 = '/home/nischay/hubmap/try_mm/mmdetection/work_dirs/hubmap/pseudo/pseudo60combpretexp5_ds1ft_20e_2048_htc50/best_segm_mAP_epoch_15.pth'\n",
    "# checkpoint_file3 = '/home/nischay/hubmap/vitadap/detection/work_dirs/pretexp4_adaplargehtc_1200_bs2_augv4/best_segm_mAP_epoch_21.pth'\\\n",
    "\n",
    "checkpoint_file3 = '/home/nischay/hubmap/vitadap/detection/work_dirs/ds12combine/beitv2ladap_exp2/f1/best_segm_mAP_epoch_18.pth'\n",
    "# checkpoint_file3 = '/home/nischay/hubmap/try_mm/mmdetection/cbnet/work_dirs/hubmap/exp2_withpret1_cbbase_1600_morepretep//kaggle/input/pretexp5-adapv2lbeithtc-cv428f1/detectors_epoch_23.pth.pth'\n",
    "model3 = init_detector(cfg3, checkpoint_file3, device='cuda:0')  # or device='cuda:0'\n",
    "\n",
    "\n",
    "sample = None\n",
    "import mmcv\n",
    "\n",
    "ids3 = []\n",
    "heights3 = []\n",
    "widths3 = []\n",
    "prediction_strings3 = []\n",
    "\n",
    "for img in tqdm(all_imgs):\n",
    "    img_array = mmcv.imread(img,channel_order='rgb')\n",
    "    [h, w, c] = img_array.shape \n",
    "    pred = inference_detector(model3,img)\n",
    "    pred_string = ''\n",
    "    #print(pred.pred_instances)\n",
    "    #print (len(pred)) #2\n",
    "    #print(pred)\n",
    "    \n",
    "    pred_class = pred[0]\n",
    "#     print(len(pred_class)) #3 class\n",
    "#     print(pred_class)\n",
    "#     print(pred_class[0].shape) #(5,5) #class 0 with 5 item\n",
    "#     print(pred_class[1].shape) #(40,5)#class 1 with 40 item\n",
    "#     print(pred_class[2].shape) #(1,5) #class 2 with 1 item\n",
    "    #print(pred.pred_instances)\n",
    "    \n",
    "    pred_mask = pred[1]\n",
    "\n",
    "                        \n",
    "    ids3.append(os.path.basename(img).split('.')[0])\n",
    "    heights3.append(h)\n",
    "    widths3.append(w)\n",
    "    prediction_strings3.append(pred)                    \n",
    "    \n",
    "    # prediction_strings.append(pred_string)                    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74072aa-e596-4d2d-bf56-dfecb412fa09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e71c851-92a4-4b4a-a6b2-f72009d4a761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "from scipy import ndimage as ndi\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "from skimage.segmentation import find_boundaries\n",
    "from skimage.morphology import binary_dilation, binary_erosion\n",
    "\n",
    "def smooth_boundary(mask_pred):\n",
    "    # Smooth boundaries by dilating and eroding\n",
    "    # smoothed_mask = binary_dilation(mask_pred)\n",
    "    # smoothed_mask = binary_erosion(smoothed_mask)\n",
    "\n",
    "    # Remove boundaries from the mask\n",
    "    boundary_mask = find_boundaries(mask_pred)\n",
    "    mask_pred = mask_pred & ~boundary_mask\n",
    "    \n",
    "    return mask_pred\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "from scipy.ndimage import convolve\n",
    "\n",
    "def weighted_post_processing(mask_pred):\n",
    "    kernel = np.array([[0.05, 0.4, 0.4],\n",
    "                       [0.05, 0.95, 0.4],\n",
    "                       [0.05, 0.4, 0.4]])\n",
    "    weights = convolve(mask_pred.astype(float), kernel, mode='constant')\n",
    "\n",
    "    # Apply weights to the mask\n",
    "    weighted_mask_pred = mask_pred * weights\n",
    "\n",
    "    return weighted_mask_pred\n",
    "# Example usage\n",
    "# mask_pred_weighted = weighted_post_processing(mask_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ed876c-3f44-4acc-8899-57123152fd5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c310dbe4-3177-403b-9e73-de7aad68ab69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pycocotools.coco as coco\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from pycocotools import mask\n",
    "from skimage.morphology import binary_dilation\n",
    "from skimage.morphology import binary_erosion, binary_dilation, binary_opening, binary_closing\n",
    "# prediction_strings2 = copy.deepcopy(ps2_copy)\n",
    "\n",
    "# Convert predictions to COCO format\n",
    "coco_preds2 = []\n",
    "\n",
    "from skimage.measure import label, regionprops\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f203eb55-9cae-4d2c-86a3-809d74262248",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_PIXELS = 40\n",
    "def nms_predictions(classes, scores, bboxes, masks, \n",
    "                    iou_th=.5, shape=(512, 512), weights=[0.5,0.5]):\n",
    "    he, wd = shape[0], shape[1]\n",
    "    boxes_list = [[x[0] / wd, x[1] / he, x[2] / wd, x[3] / he]\n",
    "                  for x in bboxes]\n",
    "    scores_list = [x for x in scores]\n",
    "    labels_list = [x for x in classes]\n",
    "    nms_bboxes, nms_scores, nms_classes = nms(\n",
    "        boxes=[boxes_list], \n",
    "        scores=[scores_list], \n",
    "        labels=[labels_list], \n",
    "        weights=weights,\n",
    "\n",
    "        iou_thr=iou_th\n",
    "    )\n",
    "                        \n",
    "    # nms_bboxes, nms_scores, nms_classes = weighted_boxes_fusion(\n",
    "    #     boxes_list=[boxes_list], \n",
    "    #     scores_list=[scores_list], \n",
    "    #     labels_list=[labels_list], \n",
    "    #     weights=weights,\n",
    "    #     conf_type='max',\n",
    "    #     iou_thr=iou_th\n",
    "    # )\n",
    "                        \n",
    "    nms_masks = []\n",
    "    for s in nms_scores:\n",
    "        nms_masks.append(masks[scores.index(s)])\n",
    "        \n",
    "        # nms_masks.append(masks[scores.index(s)])\n",
    "    nms_scores, nms_classes, nms_masks = zip(*sorted(zip(nms_scores, nms_classes, nms_masks), reverse=True))\n",
    "    return nms_classes, nms_scores, nms_masks\n",
    "\n",
    "def ensemble_pred_masks(masks, min_pixels=MIN_PIXELS, shape=(512, 512)):\n",
    "    result = []\n",
    "    used = np.zeros(shape, dtype=int) \n",
    "\n",
    "    prev_masks = []\n",
    "    new_masks = []\n",
    "    for i, mask in enumerate(masks):\n",
    "        # cont, hier = cv2.findContours(np.array(mask,dtype=np.uint8),cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        # if len(cont)>0:\n",
    "            # for cnt in cont:\n",
    "            #     convex_mask = cv2.fillConvexPoly(np.zeros_like(np.array(mask,dtype=np.uint8)),points=cnt, color=1)\n",
    "            #     fillornot = len(pd.Series((convex_mask==mask).flatten()).value_counts())\n",
    "            #     if fillornot>1: #fill\n",
    "            #         mask = convex_mask\n",
    "\n",
    "        \n",
    "            # before= mask.sum()\n",
    "        mask = binary_erosion(binary_dilation(mask))  #post processing \n",
    "            # if before!=mask.sum():\n",
    "               # print('after',mask.sum(),'before',before)\n",
    "        mask = mask * (1-used)\n",
    "        # if mask.sum() >= 60: # skip predictions with small area\n",
    "                    # used += mask \n",
    "                #     result.append(rle_encode(mask))\n",
    "        new_masks.append(mask)\n",
    "        \n",
    "    return new_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ac06fc8-6e03-449c-9fb1-93a4bd0d5ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = [prediction_strings, prediction_strings2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "43498c66-960c-4577-8b43-1c0a8e811788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "for i in prediction_strings[0][0]:\n",
    "    print(i.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "572a98a2-9e0a-47e6-a91f-4590abbb0bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(prediction_strings[0][0][0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e9a24aa1-5b19-4410-836c-fc99157cfce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction_strings2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb2f5f6-f62c-4523-8dad-612f1537204c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5a566d6-2342-4c18-a7d8-a53efadc3092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ex.wbf_tracking import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7da29e24-baeb-437a-857e-76d50318388d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ensemble_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd5165ed-906f-423c-bb2a-45d134513a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ensemble_boxes import *\n",
    "MODEL_WEIGHTS = [0.25,0.75]\n",
    "def bbox_to_key(bbox):\n",
    "    return str(np.round(bbox, 6))\n",
    "\n",
    "\n",
    "# Fuse masks that belong to fused boxes\n",
    "def get_wsf_mask(wbf_box, wbf_org, pmasks, pmasks_lkup, thres=0.5):\n",
    "    w, h = 512, 512\n",
    "    mask = np.zeros((w, h), dtype=np.uint8)\n",
    "    for i in range(len(wbf_org)):\n",
    "        key = bbox_to_key(wbf_org[i][4:])\n",
    "        model = int(wbf_org[i][3])\n",
    "        # try:\n",
    "        ind = pmasks_lkup[model][key]\n",
    "        mask = mask + pmasks[model][ind]\n",
    "        # except:\n",
    "            # pass\n",
    "    # convert thres to integer based on number of boxes\n",
    "    threshold = max(1, int(thres*len(wbf_org)))\n",
    "    # threshold = 0.0001\n",
    "            \n",
    "    # remove pixels outside WBF box\n",
    "    m2 = np.zeros((w, h), dtype=np.uint8)\n",
    "    x1 = max(0, int(h * wbf_box[0]))\n",
    "    y1 = max(0, int(w * wbf_box[1]))\n",
    "    x2 = min(h, int(h * wbf_box[2]))\n",
    "    y2 = min(w, int(w * wbf_box[3]))\n",
    "    # print(x1,x2,y1,y2)\n",
    "    m2[y1:y2, x1:x2] = 1\n",
    "    mask = (mask >= threshold) * m2\n",
    "    return mask.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "606541f0-ca26-48ce-a474-fd0c2dfdbfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_glomeruli_masks_single_image(image_id, data):\n",
    "    masks = []\n",
    "    for item in data:\n",
    "        if item[\"id\"] == image_id:\n",
    "            anns = item[\"annotations\"]\n",
    "            for an in anns:\n",
    "                category_type = an[\"type\"]\n",
    "                if category_type == \"glomerulus\":\n",
    "                    segmentation = an[\"coordinates\"]\n",
    "                    mask_img = coordinates_to_masks(segmentation, (512, 512))[0]\n",
    "                    masks.append(mask_img.astype(np.uint8))\n",
    "\n",
    "    return masks\n",
    "\n",
    "def coordinates_to_masks(coordinates, shape):\n",
    "    masks = []\n",
    "    for coord in coordinates:\n",
    "        mask = np.zeros(shape, dtype=np.uint8)\n",
    "        cv2.fillPoly(mask, [np.array(coord)], 1)\n",
    "        masks.append(mask)\n",
    "    return masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c188baaf-518d-44f1-b926-5574b4732cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonl_file_path = \"Data/polygons.jsonl\"\n",
    "data = []\n",
    "with open(jsonl_file_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        data.append(json.loads(line))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "707a648c-03a3-4b50-8222-acf167f44206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'000e79e206b7'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.basename(val_ids[0]).split('.')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3529d418-4673-4544-8b32-0dd50e63975f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'blood_vessel': 0}\n",
      "{0: 'blood_vessel'}\n",
      "[{'id': 0, 'name': 'blood_vessel'}]\n"
     ]
    }
   ],
   "source": [
    "categories_list=['blood_vessel']\n",
    "#------------------------------------------------------------------------------\n",
    "categories_ids = {name:id for id, name in enumerate(categories_list)}  \n",
    "ids_categories = {id:name for id, name in enumerate(categories_list)}  \n",
    "categories =[{'id':id,'name':name} for name,id in categories_ids.items()]\n",
    "\n",
    "print(categories_ids)\n",
    "print(ids_categories)\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d2864eb7-5272-4120-abfd-f2287d850dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json, cv2, numpy as np, itertools, random, pandas as pd\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools import mask as maskUtils\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn import model_selection\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from pycocotools.coco import COCO\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "def coordinates_to_masks(coordinates, shape):\n",
    "    masks = []\n",
    "    for coord in coordinates:\n",
    "        mask = np.zeros(shape, dtype=np.uint8)\n",
    "        cv2.fillPoly(mask, [np.array(coord)], 1)\n",
    "        masks.append(mask)\n",
    "    return masks\n",
    "\n",
    "def binary_mask_to_rle(binary_mask):\n",
    "    rle = {'counts': [], 'size': list(binary_mask.shape)}\n",
    "    counts = rle.get('counts')\n",
    "    for i, (value, elements) in enumerate(itertools.groupby(binary_mask.ravel(order='F'))):\n",
    "        if i == 0 and value == 1:\n",
    "            counts.append(0)\n",
    "        counts.append(len(list(elements)))\n",
    "    return rle\n",
    "\n",
    "def rle_to_binary_mask(mask_rle, shape=(1024, 1024)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) \n",
    "                       for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo : hi] = 1\n",
    "    return img.reshape(shape)  # Needed to align to RLE direction\n",
    "\n",
    "def coco_structure(images_ids):\n",
    "    idx=1\n",
    "    annotations=[]\n",
    "    images=[]\n",
    "    for item in tqdm(data,total=int(len(images_ids))):\n",
    "        image_id=item[\"id\"]\n",
    "        if image_id in images_ids:\n",
    "            image = {\"id\": image_id, \"file_name\": image_id + \".tif\", \"height\": 512, \"width\": 512}\n",
    "            images.append(image)\n",
    "        else:continue\n",
    "        #-----------------------------\n",
    "        anns=item[\"annotations\"]\n",
    "        for an in anns:\n",
    "            category_type=an[\"type\"]\n",
    "            if category_type ==\"blood_vessel\":\n",
    "                category_id=categories_ids[category_type]\n",
    "                segmentation=an[\"coordinates\"]\n",
    "                mask_img = coordinates_to_masks(segmentation, (512, 512))[0]\n",
    "                ys, xs = np.where(mask_img)\n",
    "                x1, x2 = min(xs), max(xs)\n",
    "                y1, y2 = min(ys), max(ys)\n",
    "\n",
    "                rle = binary_mask_to_rle(mask_img)\n",
    "\n",
    "                seg = {\n",
    "                    \"id\": idx,\n",
    "                    \"image_id\": image_id,\n",
    "                    \"category_id\": categories_ids[\"blood_vessel\"],\n",
    "                    \"segmentation\": rle,\n",
    "                    \"bbox\": [int(x1), int(y1), int(x2 - x1 + 1), int(y2 - y1 + 1)],\n",
    "                    \"area\": int(np.sum(mask_img)),\n",
    "                    \"iscrowd\": 0,\n",
    "                }\n",
    "                if image_id in images_ids:\n",
    "                    annotations.append(seg)\n",
    "                    idx=idx+1\n",
    "                \n",
    "    return {\"info\": {}, \"licenses\": [], \"categories\": categories, \"images\": images, \"annotations\": annotations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "87179182-8927-413d-8052-4dc5598f6863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_strings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b3f68f63-8749-4947-848f-f39c89500c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'000e79e206b7'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ids[0].split('/')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969887fd-cfa9-480d-ba52-5c718aced862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879506fe-1809-45ab-bdab-6d36f89a6a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b7cad5f2-a48f-40df-a619-4e1819f0aac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5e8a8b0e1884d8b80e19cc994e82369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subm_ids, subm_masks, subm_boxes = [], [], []\n",
    "from skimage import measure\n",
    "from ex.wbf_tracking import *\n",
    "\n",
    "\n",
    "idx = 1\n",
    "annotations = []\n",
    "images = []\n",
    "for id in tqdm(range(len(prediction_strings))):\n",
    "\n",
    "\n",
    "    image_id = val_ids[id].split('/')[-1].split('.')[0]\n",
    "\n",
    "    image = {\"id\": image_id, \"file_name\": image_id + \".tif\", \"height\": 512, \"width\": 512}\n",
    "    images.append(image)\n",
    "\n",
    "    masks_nms_list = []\n",
    "    pred_dict_list=  []\n",
    "    score_nms_list = []\n",
    "    box_nms_list = []\n",
    "    class_nms_list = []\n",
    "    \n",
    "    \n",
    "    for pred,weight in (zip(MODELS,MODEL_WEIGHTS)):\n",
    "        pred_dict = {}\n",
    "        previous_masks = []\n",
    "        classes_nms = []\n",
    "        scoresb_nms = []\n",
    "        bboxesb_nms = []\n",
    "        weightsb_nms = []        \n",
    "        result = pred[id]\n",
    "        \n",
    "        #find the max class \n",
    "        c = []\n",
    "        for i, classe in enumerate(result[0]):\n",
    "            #print(classe.shape)\n",
    "            c.append(classe.shape[0])\n",
    "        \n",
    "        maxclass = np.argwhere(np.array(c)==np.max(c))[0][0]\n",
    "        #print(c,test_name,classe.shape[0],np.max(c))\n",
    "        for i, classe in enumerate(result[0]):\n",
    "            if maxclass==maxclass: #classe.shape != (0, 5):\n",
    "                bbs = classe\n",
    "                sgs = result[1][i]\n",
    "                # print(sgs.shape)\n",
    "                count = 0\n",
    "                for bb, sg in zip(bbs,sgs):\n",
    "                    box = bb[:4]\n",
    "                    cnf = bb[4]\n",
    "                    box = [box[0] / 512, box[1] / 512, box[2] / 512, box[3] / 512]\n",
    "                    # box = [box[0] / 2048, box[1] / 2048, box[2] / 2048, box[3] / 2048]\n",
    "                    \n",
    "                    # print(box)\n",
    "                    # box \n",
    "                    if cnf >= 0.001:\n",
    "                        mask = np.array(sg,dtype=np.uint8)  \n",
    "                        previous_masks.append(mask)\n",
    "                        scoresb_nms.extend([cnf])\n",
    "                        bboxesb_nms.extend([box])\n",
    "                        # weights = [weight] * len()\n",
    "                        weightsb_nms.extend([weight])\n",
    "        # print(len(bboxesb_nms))\n",
    "        # print(len(scoresb_nms))\n",
    "                        pred_dict[bbox_to_key(box)] = count\n",
    "                        count+= 1\n",
    "                        classes_nms = [0] * len(previous_masks)\n",
    "                \n",
    "            masks_nms_list.append(np.array(previous_masks, dtype=np.uint8))\n",
    "            score_nms_list.append(np.array(scoresb_nms))\n",
    "            box_nms_list.append(np.array(bboxesb_nms))\n",
    "\n",
    "            class_nms_list.append(np.array(classes_nms))\n",
    "            pred_dict_list.append(pred_dict)\n",
    "\n",
    "        \n",
    "    \n",
    "    # print(len(masks_nms))\n",
    "    # print(len(classes_nms))\n",
    "\n",
    "    # print(len(scoresb_nms))\n",
    "\n",
    "    wbf_boxes, wbf_scores, _, wbf_originals = weighted_boxes_fusion_tracking(box_nms_list, \n",
    "                                                                             score_nms_list, \n",
    "                                                                             labels_list=class_nms_list, \n",
    "                                                                             iou_thr=0.6, \n",
    "                                                                             skip_box_thr=0.01)\n",
    "    # classes_nms, scores_nms, masks_nms = nms_predictions(classes_nms, scoresb_nms, bboxesb_nms, masks_nms,iou_th=0.6,weights=[0.5]) \n",
    "    # masks_nms = ensemble_pred_masks(masks_nms, classes_nms) \n",
    "    \n",
    "    fin_masks = []\n",
    "    used = np.zeros((512,512), dtype=int)\n",
    "    # print(len(wbf_boxes))\n",
    "    for i in range(len(wbf_boxes)):\n",
    "        \n",
    "        mask = get_wsf_mask(wbf_boxes[i], wbf_originals[i], masks_nms_list, pred_dict_list, thres=0.2)\n",
    "        \n",
    "        # try:\n",
    "        #     props = measure.regionprops(mask)\n",
    "        # except:\n",
    "        #     continue\n",
    "        # # # if there are multiple separated masks, pick the larger one\n",
    "        # areas = []\n",
    "        # for a in range(len(props)):\n",
    "        #     areas.append(props[a].area)\n",
    "        # try:\n",
    "        #     target = np.argmax(areas)\n",
    "        # except:\n",
    "        #     continue\n",
    "        # # extract properties of interest \n",
    "        # major_axis_len = props[target].major_axis_length\n",
    "        # check against limits\n",
    "        # if major_axis_len >= major_axis_len_min:\n",
    "        # mask = mask * (1-used)\n",
    "        # check if mask is chopped up by previous detections\n",
    "        # if len(measure.find_contours(mask, 0.5, positive_orientation='low')) == 1:\n",
    "            # used += mask\n",
    "        fin_masks.append(mask)\n",
    "            \n",
    "            # res.append(rle_encode(mask))\n",
    "        # else:\n",
    "            # print('{}: Chopped\\'n\\'dropped #{}')\n",
    "        # else:\n",
    "            # if DEBUG:\n",
    "                # print('{}: Failed limits #{}'.format(fn.split('/')[-1], i))\n",
    "\n",
    "        \n",
    "\n",
    "    # print(len(fin_masks))\n",
    "    fin_masks = ensemble_pred_masks(fin_masks) \n",
    "\n",
    "    for i in range(len(fin_masks)):\n",
    "        mask_img = fin_masks[i]\n",
    "        conf = wbf_scores[i]\n",
    "        if conf>0.5:\n",
    "            ys, xs = np.where(mask_img)\n",
    "            x1, x2 = min(xs), max(xs)\n",
    "            y1, y2 = min(ys), max(ys)\n",
    "    \n",
    "            rle = binary_mask_to_rle(mask_img)\n",
    "    \n",
    "            seg = {\n",
    "                \"id\": idx,\n",
    "                \"image_id\": image_id,\n",
    "                \"category_id\": categories_ids[\"blood_vessel\"],\n",
    "                \"segmentation\": rle,\n",
    "                \"bbox\": [int(x1), int(y1), int(x2 - x1 + 1), int(y2 - y1 + 1)],\n",
    "                \"area\": int(np.sum(mask_img)),\n",
    "                \"iscrowd\": 0,\n",
    "            }\n",
    "            annotations.append(seg)\n",
    "    \n",
    "    \n",
    "            idx += 1\n",
    "\n",
    "    if id % 100 == 0:\n",
    "        final_dict = {\"info\": {}, \"licenses\": [], \"categories\": categories, \"images\": images, \"annotations\": annotations}\n",
    "        output_file_path = f\"pseudo/exp2_ds3wsi8_coco_ensthr_50.json\"\n",
    "        with open(output_file_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "            json.dump(final_dict, output_file, ensure_ascii=True, indent=4)\n",
    "    \n",
    "    \n",
    "    # subm_masks.append(fin_masks)\n",
    "    # subm_ids.append(wbf_scores)\n",
    "    # subm_boxes.append(wbf_boxes)\n",
    "\n",
    "\n",
    "    \n",
    "        # for enc_mask in encoded_masks:\n",
    "        #     subm_ids.append(test_name[:test_name.find('.')])\n",
    "        #     subm_masks.append(enc_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1461bff5-8b1f-410f-80d8-cb4f9b76fa6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0a44ffe2-6da1-4dfa-bb01-92beb8b029a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model,model2,model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad1d695-68af-479f-bc5d-1a77d0534709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2522e85d-a339-4d61-8310-8d47fcc5ccd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def combine_coco_datasets(file1_path, file2_path):\n",
    "    # Load the JSON files\n",
    "    with open(file1_path, 'r') as file1:\n",
    "        dataset1 = json.load(file1)\n",
    "    \n",
    "    with open(file2_path, 'r') as file2:\n",
    "        dataset2 = json.load(file2)\n",
    "    \n",
    "    # Combine images and annotations\n",
    "    combined_images = dataset1['images'] + dataset2['images']\n",
    "    combined_annotations = dataset1['annotations'] + dataset2['annotations']\n",
    "    \n",
    "    # Update image and annotation IDs\n",
    "    num_images1 = len(dataset1['images'])\n",
    "    num_annotations1 = len(dataset1['annotations'])\n",
    "    num_annotations2 = len(dataset2['annotations'])\n",
    "    \n",
    "    # for image in combined_images:\n",
    "        # image['id'] += num_images1\n",
    "    for i in range(0, num_annotations1 + num_annotations2):\n",
    "        combined_annotations[i]['id'] = i\n",
    "    # for annotation in combined_annotations:\n",
    "        # annotation['id'] += num_annotations1\n",
    "        # annotation['image_id'] += num_images1\n",
    "    \n",
    "    # Create the combined dataset\n",
    "    combined_dataset = {\n",
    "        'info': {},\n",
    "        'licenses': [],\n",
    "        'categories': dataset1['categories'],  # Assuming categories are the same in both datasets\n",
    "        'images': combined_images,\n",
    "        'annotations': combined_annotations\n",
    "    }\n",
    "    \n",
    "    return combined_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8f489807-17d4-4829-b037-9324585dd3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_pseudo = combine_coco_datasets('/home/nischay/hubmap/coco/ds2wsiall_coco_1024_train_fold1.json', '/home/nischay/hubmap/pseudo/exp2_ds3wsi8_coco_ensthr_50.json')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6a1f970a-859b-4c7b-ba8a-6a94a5955c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the combined dataset to a JSON file\n",
    "with open('pseudo/50_combined_ds2wsiall_exp2pseudo.json', 'w') as output_file:\n",
    "    json.dump(combine_pseudo, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b8730174-735e-432b-acb9-713aaadaad23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2312"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (subm_masks[0])\n",
    "len(combine_pseudo['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "18d9d303-509e-4ff9-9ccd-fc7f72661cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21147"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combine_pseudo['annotations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3fe24d-cc0e-4045-9ad2-6b41f4a65a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a3f0b8cc-ab33-4386-b2dc-013865fcc2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.array(masks_nms)\n",
    "len(final_dict['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d2267a4d-3cb1-4c30-9a11-6a60e57a30f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9389"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_dict['annotations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2dee44-813a-4575-9e68-b166db25fbd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b745ce-05ed-4cfd-b5c6-7ff8ebaa3331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8677f52f-2ace-405e-ba51-b8a7b3d20808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62578fc5-65e1-48e7-b4bb-14881d21a3db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e10aa36f-83bc-4cc5-bbfe-d5c559a87c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(pred_ens_str[0][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b85944d1-a52a-4d56-9df5-8990bac1350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(pred2[1][0]+pred2[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e7f463be-2140-4072-aba8-8936386fae1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(pred_ens_str[0][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9466f7b0-9e4b-4225-b5d4-e69268c2bb62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dff949a-0409-468e-9d3a-a9b7e59bd110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d50eac6-0825-4b11-8da5-940016027957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7718cd4-ab6e-4ca4-a162-b77818fa9c34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f32d0d-862b-4f70-97c7-54e23fc5f0f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cb3901-08e2-4fd5-bdb1-f8889987e295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91825e37-8482-4a1c-b9df-4640c3860833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc6718e-6dfd-4ac6-938c-ed11f3f5c916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a0c74f-d256-4121-b6ea-92fd524b8518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146478a6-777e-4b55-9842-d7222fc00792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e4afd710",
   "metadata": {
    "papermill": {
     "duration": 0.01766,
     "end_time": "2023-06-30T10:52:46.919694",
     "exception": false,
     "start_time": "2023-06-30T10:52:46.902034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(prediction_strings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 335.814549,
   "end_time": "2023-06-30T10:52:51.102187",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-30T10:47:15.287638",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
